// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.

import { Metadata, asTextContentResult } from 'telnyx-mcp/tools/types';

import { Tool } from '@modelcontextprotocol/sdk/types.js';
import Telnyx from 'telnyx';

export const metadata: Metadata = {
  resource: 'calls.actions',
  operation: 'write',
  tags: [],
  httpMethod: 'post',
  httpPath: '/calls/{call_control_id}/actions/transcription_start',
  operationId: 'StartCallTranscription',
};

export const tool: Tool = {
  name: 'start_transcription_calls_actions',
  description:
    'Start real-time transcription. Transcription will stop on call hang-up, or can be initiated via the Transcription stop command.\n\n**Expected Webhooks:**\n\n- `call.transcription`\n',
  inputSchema: {
    type: 'object',
    properties: {
      call_control_id: {
        type: 'string',
      },
      client_state: {
        type: 'string',
        description:
          'Use this field to add state to every subsequent webhook. It must be a valid Base-64 encoded string.',
      },
      command_id: {
        type: 'string',
        description:
          'Use this field to avoid duplicate commands. Telnyx will ignore any command with the same `command_id` for the same `call_control_id`.',
      },
      transcription_engine: {
        type: 'string',
        description:
          'Engine to use for speech recognition. Legacy values `A` - `Google`, `B` - `Telnyx` are supported for backward compatibility.',
        enum: ['Google', 'Telnyx', 'Deepgram', 'A', 'B'],
      },
      transcription_engine_config: {
        anyOf: [
          {
            type: 'object',
            title: 'Transcription engine Google config',
            properties: {
              enable_speaker_diarization: {
                type: 'boolean',
                description: 'Enables speaker diarization.',
              },
              hints: {
                type: 'array',
                description: 'Hints to improve transcription accuracy.',
                items: {
                  type: 'string',
                },
              },
              interim_results: {
                type: 'boolean',
                description:
                  'Whether to send also interim results. If set to false, only final results will be sent.',
              },
              language: {
                $ref: '#/$defs/google_transcription_language',
              },
              max_speaker_count: {
                type: 'integer',
                description: 'Defines maximum number of speakers in the conversation.',
              },
              min_speaker_count: {
                type: 'integer',
                description: 'Defines minimum number of speakers in the conversation.',
              },
              model: {
                type: 'string',
                description: 'The model to use for transcription.',
                enum: [
                  'latest_long',
                  'latest_short',
                  'command_and_search',
                  'phone_call',
                  'video',
                  'default',
                  'medical_conversation',
                  'medical_dictation',
                ],
              },
              profanity_filter: {
                type: 'boolean',
                description: 'Enables profanity_filter.',
              },
              speech_context: {
                type: 'array',
                description: 'Speech context to improve transcription accuracy.',
                items: {
                  type: 'object',
                  properties: {
                    boost: {
                      type: 'number',
                      description: 'Boost factor for the speech context.',
                    },
                    phrases: {
                      type: 'array',
                      items: {
                        type: 'string',
                      },
                    },
                  },
                },
              },
              transcription_engine: {
                type: 'string',
                description: 'Engine identifier for Google transcription service',
                enum: ['Google'],
              },
              use_enhanced: {
                type: 'boolean',
                description:
                  'Enables enhanced transcription, this works for models `phone_call` and `video`.',
              },
            },
          },
          {
            type: 'object',
            title: 'Transcription engine Telnyx config',
            properties: {
              language: {
                $ref: '#/$defs/telnyx_transcription_language',
              },
              transcription_engine: {
                type: 'string',
                description: 'Engine identifier for Telnyx transcription service',
                enum: ['Telnyx'],
              },
              transcription_model: {
                type: 'string',
                description: 'The model to use for transcription.',
                enum: ['openai/whisper-tiny', 'openai/whisper-large-v3-turbo'],
              },
            },
          },
          {
            type: 'object',
            title: 'Transcription engine Deepgram config',
            properties: {
              transcription_engine: {
                type: 'string',
                description: 'Engine identifier for Deepgram transcription service',
                enum: ['Deepgram'],
              },
              transcription_model: {
                type: 'string',
                description: 'The model to use for transcription.',
                enum: ['deepgram/nova-2', 'deepgram/nova-3'],
              },
              language: {
                type: 'string',
                description:
                  'Language to use for speech recognition. Available languages depend on the selected model.',
                enum: [
                  'bg',
                  'ca',
                  'zh',
                  'zh-CN',
                  'zh-Hans',
                  'zh-TW',
                  'zh-Hant',
                  'zh-HK',
                  'cs',
                  'da',
                  'da-DK',
                  'nl',
                  'en',
                  'en-US',
                  'en-AU',
                  'en-GB',
                  'en-NZ',
                  'en-IN',
                  'et',
                  'fi',
                  'nl-BE',
                  'fr',
                  'fr-CA',
                  'de',
                  'de-CH',
                  'el',
                  'hi',
                  'hu',
                  'id',
                  'it',
                  'ja',
                  'ko',
                  'ko-KR',
                  'lv',
                  'lt',
                  'ms',
                  'no',
                  'pl',
                  'pt',
                  'pt-BR',
                  'pt-PT',
                  'ro',
                  'ru',
                  'sk',
                  'es',
                  'es-419',
                  'sv',
                  'sv-SE',
                  'th',
                  'th-TH',
                  'tr',
                  'uk',
                  'vi',
                  'auto_detect',
                ],
              },
            },
            required: ['transcription_engine', 'transcription_model'],
          },
          {
            $ref: '#/$defs/transcription_engine_a_config',
          },
          {
            $ref: '#/$defs/transcription_engine_b_config',
          },
        ],
      },
      transcription_tracks: {
        type: 'string',
        description:
          'Indicates which leg of the call will be transcribed. Use `inbound` for the leg that requested the transcription, `outbound` for the other leg, and `both` for both legs of the call. Will default to `inbound`.',
      },
    },
    required: ['call_control_id'],
    $defs: {
      google_transcription_language: {
        type: 'string',
        title: 'Google transcription engine list of languages',
        description: 'Language to use for speech recognition',
        enum: [
          'af',
          'sq',
          'am',
          'ar',
          'hy',
          'az',
          'eu',
          'bn',
          'bs',
          'bg',
          'my',
          'ca',
          'yue',
          'zh',
          'hr',
          'cs',
          'da',
          'nl',
          'en',
          'et',
          'fil',
          'fi',
          'fr',
          'gl',
          'ka',
          'de',
          'el',
          'gu',
          'iw',
          'hi',
          'hu',
          'is',
          'id',
          'it',
          'ja',
          'jv',
          'kn',
          'kk',
          'km',
          'ko',
          'lo',
          'lv',
          'lt',
          'mk',
          'ms',
          'ml',
          'mr',
          'mn',
          'ne',
          'no',
          'fa',
          'pl',
          'pt',
          'pa',
          'ro',
          'ru',
          'rw',
          'sr',
          'si',
          'sk',
          'sl',
          'ss',
          'st',
          'es',
          'su',
          'sw',
          'sv',
          'ta',
          'te',
          'th',
          'tn',
          'tr',
          'ts',
          'uk',
          'ur',
          'uz',
          've',
          'vi',
          'xh',
          'zu',
        ],
      },
      telnyx_transcription_language: {
        type: 'string',
        title: 'Telnyx transcription engine list of languages',
        description: 'Language to use for speech recognition',
        enum: [
          'en',
          'zh',
          'de',
          'es',
          'ru',
          'ko',
          'fr',
          'ja',
          'pt',
          'tr',
          'pl',
          'ca',
          'nl',
          'ar',
          'sv',
          'it',
          'id',
          'hi',
          'fi',
          'vi',
          'he',
          'uk',
          'el',
          'ms',
          'cs',
          'ro',
          'da',
          'hu',
          'ta',
          'no',
          'th',
          'ur',
          'hr',
          'bg',
          'lt',
          'la',
          'mi',
          'ml',
          'cy',
          'sk',
          'te',
          'fa',
          'lv',
          'bn',
          'sr',
          'az',
          'sl',
          'kn',
          'et',
          'mk',
          'br',
          'eu',
          'is',
          'hy',
          'ne',
          'mn',
          'bs',
          'kk',
          'sq',
          'sw',
          'gl',
          'mr',
          'pa',
          'si',
          'km',
          'sn',
          'yo',
          'so',
          'af',
          'oc',
          'ka',
          'be',
          'tg',
          'sd',
          'gu',
          'am',
          'yi',
          'lo',
          'uz',
          'fo',
          'ht',
          'ps',
          'tk',
          'nn',
          'mt',
          'sa',
          'lb',
          'my',
          'bo',
          'tl',
          'mg',
          'as',
          'tt',
          'haw',
          'ln',
          'ha',
          'ba',
          'jw',
          'su',
          'auto_detect',
        ],
      },
      transcription_engine_a_config: {
        type: 'object',
        title: 'Transcription engine A config',
        properties: {
          enable_speaker_diarization: {
            type: 'boolean',
            description: 'Enables speaker diarization.',
          },
          hints: {
            type: 'array',
            description: 'Hints to improve transcription accuracy.',
            items: {
              type: 'string',
            },
          },
          interim_results: {
            type: 'boolean',
            description:
              'Whether to send also interim results. If set to false, only final results will be sent.',
          },
          language: {
            $ref: '#/$defs/google_transcription_language',
          },
          max_speaker_count: {
            type: 'integer',
            description: 'Defines maximum number of speakers in the conversation.',
          },
          min_speaker_count: {
            type: 'integer',
            description: 'Defines minimum number of speakers in the conversation.',
          },
          model: {
            type: 'string',
            description: 'The model to use for transcription.',
            enum: [
              'latest_long',
              'latest_short',
              'command_and_search',
              'phone_call',
              'video',
              'default',
              'medical_conversation',
              'medical_dictation',
            ],
          },
          profanity_filter: {
            type: 'boolean',
            description: 'Enables profanity_filter.',
          },
          speech_context: {
            type: 'array',
            description: 'Speech context to improve transcription accuracy.',
            items: {
              type: 'object',
              properties: {
                boost: {
                  type: 'number',
                  description: 'Boost factor for the speech context.',
                },
                phrases: {
                  type: 'array',
                  items: {
                    type: 'string',
                  },
                },
              },
            },
          },
          transcription_engine: {
            type: 'string',
            description: 'Engine identifier for Google transcription service',
            enum: ['A'],
          },
          use_enhanced: {
            type: 'boolean',
            description: 'Enables enhanced transcription, this works for models `phone_call` and `video`.',
          },
        },
      },
      transcription_engine_b_config: {
        type: 'object',
        title: 'Transcription engine B config',
        properties: {
          language: {
            $ref: '#/$defs/telnyx_transcription_language',
          },
          transcription_engine: {
            type: 'string',
            description: 'Engine identifier for Telnyx transcription service',
            enum: ['B'],
          },
          transcription_model: {
            type: 'string',
            description: 'The model to use for transcription.',
            enum: ['openai/whisper-tiny', 'openai/whisper-large-v3-turbo'],
          },
        },
      },
    },
  },
  annotations: {},
};

export const handler = async (client: Telnyx, args: Record<string, unknown> | undefined) => {
  const { call_control_id, ...body } = args as any;
  return asTextContentResult(await client.calls.actions.startTranscription(call_control_id, body));
};

export default { metadata, tool, handler };
